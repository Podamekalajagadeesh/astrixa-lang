# STEP 34 - Visual Architecture & Data Flow

## ğŸ—ï¸ Compiler Architecture

### High-Level Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ASTRIXA COMPILER                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 1: Source Code (input)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                               â”‚
â”‚  fn greet {                                                   â”‚
â”‚  }                                                            â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
Step 2: Lexer (text â†’ tokens)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Lexer::new() â†’ next_token() â†’ Token                         â”‚
â”‚                                                               â”‚
â”‚  Input:  "fn greet {}"                                       â”‚
â”‚  Output: [Fn, Identifier("greet"), LBrace, RBrace, EOF]     â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
Step 3: Parser (tokens â†’ AST)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Parser::new() â†’ parse() â†’ Vec<Stmt>                        â”‚
â”‚                                                               â”‚
â”‚  Input:  Tokens stream                                       â”‚
â”‚  Output: [Function { name: "greet", body: [] }]             â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
Step 4: AST Visualization (output)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                               â”‚
â”‚  [                                                            â”‚
â”‚      Function {                                               â”‚
â”‚          name: "greet",                                       â”‚
â”‚          body: [],                                            â”‚
â”‚      }                                                        â”‚
â”‚  ]                                                            â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Component Relationships

### Direct Dependencies

```
main.rs
  â”œâ”€> uses: Lexer, Parser
  â”œâ”€> produces: AST output
  â”‚
â”œâ”€> Lexer (lexer.rs)
â”‚   â”œâ”€> uses: Token enum
â”‚   â””â”€> produces: Token stream
â”‚
â”œâ”€> Parser (parser.rs)
â”‚   â”œâ”€> uses: Lexer, Token, Stmt
â”‚   â””â”€> produces: Vec<Stmt>
â”‚
â”œâ”€> Token (token.rs)
â”‚   â””â”€> defines: All token types
â”‚
â””â”€> AST (ast.rs)
    â”œâ”€> defines: Expr enum
    â””â”€> defines: Stmt enum
```

---

## ğŸ”„ Data Transformations

### Transformation 1: Lexing

```
Input String
"fn greet {"

    â†“ (character by character)

Lexer
â€¢ Check if whitespace â†’ skip
â€¢ Check if '(' or ')' or '{' or '}' â†’ single token
â€¢ Check if alphabetic â†’ read_identifier()
  â€¢ Accumulate alphanumeric chars
  â€¢ Check if matches keyword â†’ keyword token
  â€¢ Otherwise â†’ Identifier token

    â†“

Output Tokens
[
  Token::Fn,
  Token::Identifier("greet"),
  Token::LBrace,
  Token::RBrace,
  Token::EOF
]
```

### Transformation 2: Parsing

```
Input Token Stream
[Fn, Identifier("greet"), LBrace, RBrace, EOF]

    â†“ (token by token)

Parser
Loop: while current != EOF
  if current == Fn:
    parse_function()
      â€¢ advance() - consume Fn
      â€¢ extract name from Identifier
      â€¢ advance() - consume name
      â€¢ create Stmt::Function
  else:
    advance()

    â†“

Output AST
[
  Function {
    name: "greet",
    body: []
  }
]
```

### Transformation 3: Visualization

```
Input AST
[Function { name: "greet", body: [] }]

    â†“

Format
println!("{:#?}", ast)
Uses Debug derive macro
Pretty-prints with indentation

    â†“

Output
[
    Function {
        name: "greet",
        body: [],
    }
]
```

---

## ğŸ—‚ï¸ Module Structure

```
compiler/
â”‚
â”œâ”€â”€ src/
â”‚   â”‚
â”‚   â”œâ”€â”€ main.rs âœ…
â”‚   â”‚   â”œâ”€â”€ mod lexer
â”‚   â”‚   â”œâ”€â”€ mod parser
â”‚   â”‚   â”œâ”€â”€ mod token
â”‚   â”‚   â”œâ”€â”€ mod ast
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ fn main()
â”‚   â”‚       â”œâ”€â”€ Create Lexer
â”‚   â”‚       â”œâ”€â”€ Create Parser
â”‚   â”‚       â”œâ”€â”€ Call parse()
â”‚   â”‚       â””â”€â”€ Print AST
â”‚   â”‚
â”‚   â”œâ”€â”€ token.rs âœ…
â”‚   â”‚   â””â”€â”€ pub enum Token
â”‚   â”‚       â”œâ”€â”€ Keywords: Fn, Let, Return
â”‚   â”‚       â”œâ”€â”€ Literals: Identifier, Number, String
â”‚   â”‚       â”œâ”€â”€ Symbols: LParen, RParen, etc.
â”‚   â”‚       â”œâ”€â”€ Operators: Plus, Minus, etc.
â”‚   â”‚       â””â”€â”€ Special: EOF
â”‚   â”‚
â”‚   â”œâ”€â”€ lexer.rs âœ…
â”‚   â”‚   â”œâ”€â”€ pub struct Lexer
â”‚   â”‚   â”œâ”€â”€ pub fn new()
â”‚   â”‚   â”œâ”€â”€ pub fn next_token()
â”‚   â”‚   â”œâ”€â”€ fn simple()
â”‚   â”‚   â”œâ”€â”€ fn skip_whitespace()
â”‚   â”‚   â””â”€â”€ fn read_identifier()
â”‚   â”‚
â”‚   â”œâ”€â”€ parser.rs âœ…
â”‚   â”‚   â”œâ”€â”€ pub struct Parser
â”‚   â”‚   â”œâ”€â”€ pub fn new()
â”‚   â”‚   â”œâ”€â”€ pub fn parse()
â”‚   â”‚   â”œâ”€â”€ fn advance()
â”‚   â”‚   â””â”€â”€ fn parse_function()
â”‚   â”‚
â”‚   â””â”€â”€ ast.rs âœ…
â”‚       â”œâ”€â”€ pub enum Expr
â”‚       â”‚   â”œâ”€â”€ Number(i64)
â”‚       â”‚   â””â”€â”€ Identifier(String)
â”‚       â”‚
â”‚       â””â”€â”€ pub enum Stmt
â”‚           â””â”€â”€ Function { name, body }
â”‚
â””â”€â”€ Cargo.toml âœ…
    â”œâ”€â”€ name = "astrixa"
    â””â”€â”€ dependencies = [...]
```

---

## ğŸ”€ Control Flow

### Main Execution Flow

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   START     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Define source code string    â”‚
            â”‚ r#"fn greet { }"#            â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Create Lexer                 â”‚
            â”‚ Lexer::new(source)           â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Create Parser                â”‚
            â”‚ Parser::new(lexer)           â”‚
            â”‚ â€¢ read first token           â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Parse Program                â”‚
            â”‚ parser.parse()               â”‚
            â”‚ â€¢ loop through tokens        â”‚
            â”‚ â€¢ build AST                  â”‚
            â”‚ â€¢ return Vec<Stmt>          â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Format and Print             â”‚
            â”‚ println!("{:#?}", ast)       â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     END     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Lexer State Machine

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   START  â”‚
                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
                         â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                             â”‚
           â–¼                             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Skip space   â”‚         â”‚ Is EOF?          â”‚
    â”‚ Advance pos  â”‚         â”‚ Return EOF token â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Match current char   â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚             â”‚          â”‚          â”‚
    â–¼             â–¼          â–¼          â–¼
  ( ) { }     + - * /      :  ,      Other
   â”‚  â”‚  â”‚ â”‚    â”‚ â”‚ â”‚ â”‚    â”‚  â”‚       â”‚
   â–¼  â–¼  â–¼ â–¼    â–¼ â–¼ â–¼ â–¼    â–¼  â–¼       â–¼
  LParen RParen Plus Minus Colon Comma read_identifier()
  RBrace RBrace Star Slash         â”‚
                                    â–¼
                              Collect alphanumeric
                                    â”‚
                              Check if keyword
                                    â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼               â–¼               â–¼
                   "fn"           "let"          other
                    â”‚               â”‚               â”‚
                    â–¼               â–¼               â–¼
                  Token::Fn    Token::Let    Token::Identifier
```

---

## ğŸ“Š Data Structure Diagram

### Token Enum

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Token Enum                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  Keywords (Unit variants)                   â”‚
â”‚  â”œâ”€ Fn                                      â”‚
â”‚  â”œâ”€ Let                                     â”‚
â”‚  â””â”€ Return                                  â”‚
â”‚                                             â”‚
â”‚  Data variants (with values)                â”‚
â”‚  â”œâ”€ Identifier(String)                      â”‚
â”‚  â”œâ”€ Number(i64)                             â”‚
â”‚  â””â”€ String(String)                          â”‚
â”‚                                             â”‚
â”‚  Punctuation (Unit variants)                â”‚
â”‚  â”œâ”€ LParen, RParen                          â”‚
â”‚  â”œâ”€ LBrace, RBrace                          â”‚
â”‚  â”œâ”€ Colon, Comma, Arrow                     â”‚
â”‚                                             â”‚
â”‚  Operators (Unit variants)                  â”‚
â”‚  â”œâ”€ Plus, Minus                             â”‚
â”‚  â”œâ”€ Star, Slash                             â”‚
â”‚  â””â”€ Equal                                   â”‚
â”‚                                             â”‚
â”‚  Special                                    â”‚
â”‚  â””â”€ EOF                                     â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### AST Structure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Stmt Enum (Statement)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  Function {                                 â”‚
â”‚    name: String,                            â”‚
â”‚    body: Vec<Stmt>                          â”‚
â”‚  }                                          â”‚
â”‚                                             â”‚
â”‚  (more variants to come in future steps)   â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             Expr Enum (Expression)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  Number(i64)                                â”‚
â”‚  Identifier(String)                         â”‚
â”‚                                             â”‚
â”‚  (more variants to come in future steps)   â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”€ Lexer State Transitions

```
Initial: position = 0, input = ['f', 'n', ' ', 'g', 'r', 'e', 'e', 't', ...]

next_token():
  â”‚
  â”œâ”€> skip_whitespace()
  â”‚   position = 0 (not whitespace, no change)
  â”‚
  â”œâ”€> ch = input[0] = 'f'
  â”‚
  â””â”€> Match 'f':
      matches "_" branch
      â†’ read_identifier()
         position_start = 0
         Loop: while position < len && is_alphanumeric
           position becomes 1, 2 (accumulate "fn")
           position = 2, input[2] = ' ' (not alphanumeric, stop)
         text = "fn"
         Match "fn":
           â†’ return Token::Fn, position = 2

Next: position = 2, input = [' ', 'g', 'r', ...]

next_token():
  â”‚
  â”œâ”€> skip_whitespace()
  â”‚   position = 2 â†’ 3 (skip space)
  â”‚
  â”œâ”€> ch = input[3] = 'g'
  â”‚
  â””â”€> Match 'g':
      matches "_" branch
      â†’ read_identifier()
         ... (accumulate "greet")
         â†’ return Token::Identifier("greet"), position = 8
```

---

## ğŸ¯ Pipeline Example Walkthrough

### Input: `fn greet { }`

**Step 1: Create Lexer**
```
Lexer {
  input: ['f', 'n', ' ', 'g', 'r', 'e', 'e', 't', ' ', '{', ' ', '}'],
  position: 0
}
```

**Step 2: Create Parser & Read First Token**
```
position = 0
next_token() â†’ Token::Fn
Parser {
  lexer: Lexer { ... },
  current: Token::Fn
}
```

**Step 3: Parse Loop**
```
Iteration 1:
  current = Token::Fn (matches!)
  parse_function()
    advance() â†’ current = Token::Identifier("greet")
    extract name = "greet"
    advance() â†’ current = Token::LBrace
    create Stmt::Function { name: "greet", body: [] }
    return Stmt::Function

Iteration 2:
  current = Token::LBrace (not Fn)
  advance() â†’ current = Token::RBrace

Iteration 3:
  current = Token::RBrace (not Fn)
  advance() â†’ current = Token::EOF

Loop ends: current == EOF
return Vec containing Function statement
```

**Step 4: Output**
```
[
    Function {
        name: "greet",
        body: [],
    }
]
```

---

## ğŸ“ˆ Complexity Analysis

### Lexer
- **Time:** O(n) where n = number of characters
- **Space:** O(n) for storing characters vector
- **Reason:** Each character processed once

### Parser
- **Time:** O(m) where m = number of tokens
- **Space:** O(h) where h = AST height
- **Reason:** Each token processed once, AST size depends on nesting

### Overall Pipeline
- **Time:** O(n) dominated by lexer
- **Space:** O(n + h) for lexer input + AST

---

## ğŸš€ Extension Points

```
Current: Text â†’ Lexer â†’ Parser â†’ AST â†’ Output

Future extensions:

Option 1: Add TypeChecker
Text â†’ Lexer â†’ Parser â†’ TypeChecker â†’ AST with types â†’ Output

Option 2: Add Codegen
Text â†’ Lexer â†’ Parser â†’ Codegen â†’ Bytecode â†’ Output

Option 3: Add Interpreter
Text â†’ Lexer â†’ Parser â†’ Interpreter â†’ Results â†’ Output

All build on this foundation!
```

---

**Status:** STEP 34 âœ… COMPLETE  
**Date:** January 9, 2026  
**Next:** Enhance AST, add expression parsing, implement type checking
